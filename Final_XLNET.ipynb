{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBnZgq5YW9LG"
      },
      "outputs": [],
      "source": [
        "# XLNET version 2 with KFold Cross Validation.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "id": "TcggZE46XCQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "94zRh21xXCsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==2.9.0\n",
        "!pip install pytorch_lightning==0.7.5"
      ],
      "metadata": {
        "id": "L8brh0uhXCvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import math\n",
        "import torch\n",
        "# import torch.nn as nn\n",
        "from torch.nn import BCEWithLogitsLoss, NLLLoss\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "# from pytorch_transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import AdamW, XLNetTokenizer, XLNetModel, TFXLNetModel, XLNetLMHeadModel, XLNetConfig, XLNetForSequenceClassification\n",
        "from keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import unicodedata\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,roc_auc_score\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import plotly\n",
        "import seaborn as sns\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "from collections import Counter\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "j89FUl2fXCxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "results = []\n",
        "n=5\n",
        "kf = KFold(n_splits=n, shuffle=True)\n",
        "\n",
        "df = pd.read_csv(\"final.csv\")\n",
        "df.drop(['id'], inplace=True, axis = 1)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df.columns = ['isHate', 'text']\n",
        "df['isHate'].value_counts()"
      ],
      "metadata": {
        "id": "7N0CeIZqXC0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "df = shuffle(df)"
      ],
      "metadata": {
        "id": "fKef9ss6XC2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = df['isHate'].value_counts()\n",
        "#temp = pd.DataFrame(temp,columns=['label','counts'])\n",
        "temp = pd.DataFrame(temp).reset_index()\n",
        "temp.columns=['label','counts']"
      ],
      "metadata": {
        "id": "hzP8lztFXC5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train ,test = train_test_split(df, random_state=2018, test_size=0.15)\n",
        "\n",
        "print('Number of training sentences: {:,}\\n'.format(train.shape[0]))\n",
        "print('Number of testing sentences: {:,}\\n'.format(test.shape[0]))\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import re\n",
        "# import emoji\n",
        "from bs4 import BeautifulSoup\n",
        "import itertools\n",
        "\n",
        "tok = WordPunctTokenizer()\n",
        "pat1 = r'@[A-Za-z0-9]+'\n",
        "pat2 = r'https?://[A-Za-z0-9./]+'\n",
        "\n",
        "\n",
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def preprocess_sentence_english(w):\n",
        "  w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "  #w = re.sub(r'[^Ɔ-ɔɛƐ]+', r' ', w)\n",
        "  #strip() Parameters\n",
        "  #chars (optional) - a string specifying the set of characters to be removed.\n",
        "  #If the chars argument is not provided, all leading and trailing whitespaces are removed from the string.\n",
        "  w = w.rstrip().strip()\n",
        "\n",
        "\n",
        "  # Fix misspelled words\n",
        "  w = ''.join(''.join(s)[:2] for _, s in itertools.groupby(w))# checking that each character should occur not more than 2 times in every word\n",
        "\n",
        "  # Tokenizing ,change cases & join together to remove unneccessary white spaces\n",
        "  w = tok.tokenize(w)\n",
        "  w = (\" \".join(w)).strip()\n",
        "  return w"
      ],
      "metadata": {
        "id": "a7rrv_GvXC7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer, XLNetLMHeadModel\n",
        "import torch\n",
        "\n",
        "tokenizer = XLNetTokenizer.from_pretrained('xlnet-large-cased')\n",
        "model = XLNetLMHeadModel.from_pretrained('xlnet-large-cased')\n",
        "\n",
        "# We show how to setup inputs to predict a next token using a bi-directional context.\n",
        "input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is very <mask>\", add_special_tokens=False)).unsqueeze(0)  # We will predict the masked token\n",
        "perm_mask = torch.zeros((1, input_ids.shape[1], input_ids.shape[1]), dtype=torch.float)\n",
        "perm_mask[:, :, -1] = 1.0  # Previous tokens don't see last token\n",
        "target_mapping = torch.zeros((1, 1, input_ids.shape[1]), dtype=torch.float)  # Shape [1, 1, seq_length] => let's predict one token\n",
        "target_mapping[0, 0, -1] = 1.0  # Our first (and only) prediction will be the last token of the sequence (the masked token)"
      ],
      "metadata": {
        "id": "UDM_gnaKXC-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
        "tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)\n",
        "\n",
        "token_lens = []\n",
        "\n",
        "for txt in df['text']:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))\n",
        "\n",
        "\n",
        "df[\"token_length\"]  = token_lens\n"
      ],
      "metadata": {
        "id": "wn9jdyb3XDA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.figure_factory as ff\n",
        "import numpy as np\n",
        "\n",
        "# Group data together\n",
        "hist_data = [df[df.isHate==0][\"token_length\"], df[df.isHate==1][\"token_length\"]]\n",
        "\n",
        "group_labels = ['Non-Hate', 'Hate']\n",
        "colors = ['slategray', 'magenta']\n",
        "\n",
        "# Create distplot with custom bin_size\n",
        "fig = ff.create_distplot(hist_data, group_labels, bin_size=.2,\n",
        "                          curve_type='normal', # override default 'kde'\n",
        "                         colors=colors)\n",
        "#fig = ff.create_distplot(hist_data, group_labels, show_hist=False, colors=colors)\n",
        "# Add title\n",
        "#fig.update_layout(title_text='Distribution of Text Token Counts')\n",
        "fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True)\n",
        "fig.update_layout(xaxis_range=[0,600])\n",
        "fig.update_layout(yaxis_range=[0,0.04])\n",
        "fig.update_layout( template=\"plotly\")\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1000,\n",
        "    height=600,)\n",
        "fig.update_layout(\n",
        "    title=\" Distribution of Text Token Length\",\n",
        "    xaxis_title=\"Token Length\",\n",
        "    yaxis_title=\"Frequency\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "eJvQUWp9XDDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaning tweets\n",
        "train['text_cleaned'] = list(map(lambda x: preprocess_sentence_english(x),train['text']) )\n",
        "test['text_cleaned'] = list(map(lambda x: preprocess_sentence_english(x),test['text']) )\n",
        "sentences = train.text_cleaned.values\n",
        "labels = train.isHate.values\n",
        "sentences[0:5]\n"
      ],
      "metadata": {
        "id": "RjP7f_7IXDF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import XLNetTokenizer, XLNetModel\n",
        "PRE_TRAINED_MODEL_NAME = 'xlnet-base-cased'\n",
        "tokenizer = XLNetTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case=True)\n",
        "print(' Original sentence {}: '.format( sentences[1]))\n",
        "\n",
        "print('Tokenized sentence {}:  '.format(tokenizer.tokenize(sentences[1])))\n",
        "\n",
        "# Print the tweet mapped to token ids.\n",
        "print('Token IDs  {}: '.format(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[1]))))\n",
        "\n",
        "def tokenize_inputs(text_list, tokenizer, num_embeddings=120):\n",
        "    \"\"\"\n",
        "    Tokenizes the input text input into ids. Appends the appropriate special\n",
        "    characters to the end of the text to denote end of sentence. Truncate or pad\n",
        "    the appropriate sequence length.\n",
        "    \"\"\"\n",
        "    # tokenize the text, then truncate sequence to the desired length minus 2 for\n",
        "    # the 2 special characters\n",
        "    tokenized_texts = list(map(lambda t: tokenizer.tokenize(t)[:num_embeddings-2], text_list))\n",
        "    # convert tokenized text into numeric ids for the appropriate LM\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    # append special token \"<s>\" and </s> to end of sentence\n",
        "    input_ids = [tokenizer.build_inputs_with_special_tokens(x) for x in input_ids]\n",
        "    # pad sequences\n",
        "    input_ids = pad_sequences(input_ids, maxlen=num_embeddings, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    return input_ids\n",
        "\n",
        "def create_attn_masks(input_ids):\n",
        "    \"\"\"\n",
        "    Create attention masks to tell model whether attention should be applied to\n",
        "    the input id tokens. Do not want to perform attention on padding tokens.\n",
        "    \"\"\"\n",
        "    # Create attention masks\n",
        "    attention_masks = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "    return attention_masks\n",
        "\n"
      ],
      "metadata": {
        "id": "mwsQT3Y6XDH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = tokenize_inputs(sentences, tokenizer, num_embeddings=120)\n",
        "attention_masks = create_attn_masks(input_ids)\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "# input_ids = torch.cat(input_ids, dim=0)\n",
        "# attention_masks = torch.cat(attention_masks, dim=0)\n",
        "input_ids = torch.from_numpy(input_ids)\n",
        "attention_masks = torch.tensor(attention_masks)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[1])\n",
        "print('Token IDs:', input_ids[1])\n",
        "print('Token IDs:', attention_masks[1])"
      ],
      "metadata": {
        "id": "jYvDEGQUXbgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "KYfmkVgVXbjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 80-20 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Checking whether the distribution of target is consitent across both the sets\n",
        "label_temp_list = []\n",
        "for a,b,c in train_dataset:\n",
        "  label_temp_list.append(c)\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} training samples with hate speech'.format(sum(label_temp_list)))\n",
        "\n",
        "label_temp_list = []\n",
        "for a,b,c in val_dataset:\n",
        "  label_temp_list.append(c)\n",
        "\n",
        "print('{:>5,} validation samples'.format(val_size))\n",
        "print('{:>5,} validation samples with hatespeech'.format(sum(label_temp_list)))"
      ],
      "metadata": {
        "id": "jIjOyfxmXblz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ],
      "metadata": {
        "id": "bHgdioptXbn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. Batch size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "TmaLWGIwXbqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class XLNetForMultiLabelSequenceClassification(torch.nn.Module):\n",
        "  def __init__(self, num_labels=2):\n",
        "    super(XLNetForMultiLabelSequenceClassification, self).__init__()\n",
        "    self.num_labels = num_labels\n",
        "    self.xlnet = XLNetModel.from_pretrained('xlnet-base-cased')\n",
        "    self.classifier = torch.nn.Linear(768, num_labels)\n",
        "\n",
        "    torch.nn.init.xavier_normal_(self.classifier.weight)\n",
        "\n",
        "  def forward(self, input_ids, token_type_ids=None,\\\n",
        "              attention_mask=None, labels=None):\n",
        "\n",
        "    # last hidden layer\n",
        "    last_hidden_state = self.xlnet(input_ids=input_ids,\\\n",
        "                                   attention_mask=attention_mask,\\\n",
        "                                   token_type_ids=token_type_ids\n",
        "                                  )\n",
        "    # pool the outputs into a mean vector\n",
        "    mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
        "    logits = self.classifier(mean_last_hidden_state)\n",
        "\n",
        "    logits = logits[:, 1] - logits[:, 0]\n",
        "    if labels is not None:\n",
        "\n",
        "      loss = BCEWithLogitsLoss()(logits, labels.float())\n",
        "#\n",
        "\n",
        "      return loss\n",
        "    else:\n",
        "      return logits\n",
        "\n",
        "  def freeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Freeze XLNet weight parameters. They will not be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def unfreeze_xlnet_decoder(self):\n",
        "    \"\"\"\n",
        "    Unfreeze XLNet weight parameters. They will be updated during training.\n",
        "    \"\"\"\n",
        "    for param in self.xlnet.parameters():\n",
        "      param.requires_grad = True\n",
        "  def pool_hidden_state(self, last_hidden_state):\n",
        "    \"\"\"\n",
        "    Pool the output vectors into a single mean vector\n",
        "    \"\"\"\n",
        "    last_hidden_state = last_hidden_state[0]\n",
        "    mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
        "    return mean_last_hidden_state\n",
        "\n"
      ],
      "metadata": {
        "id": "LfC3asveXbsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = XLNetForMultiLabelSequenceClassification(num_labels=len(labels.unique()))\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "                                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "                                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "metadata": {
        "id": "UO8e0htdXsIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "yHxUa5BOXsKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/XLNET'"
      ],
      "metadata": {
        "id": "MBxTKGBuXsM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to save and load the model form a specific epoch\n",
        "def save_model(model, save_path, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist):\n",
        "  \"\"\"\n",
        "  Save the model to the path directory provided\n",
        "  \"\"\"\n",
        "  model_to_save = model.module if hasattr(model, 'module') else model\n",
        "  checkpoint = {'epochs': epochs, \\\n",
        "                'lowest_eval_loss': lowest_eval_loss,\\\n",
        "                'state_dict': model_to_save.state_dict(),\\\n",
        "                'train_loss_hist': train_loss_hist,\\\n",
        "                'valid_loss_hist': valid_loss_hist,\\\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "               }\n",
        "\n",
        "  torch.save(checkpoint, save_path)\n",
        "  print(\"Saving model at epoch {} with validation loss of {}\".format(epochs,\\\n",
        "                                                                     lowest_eval_loss))\n",
        "  return\n",
        "def load_model(save_path):\n",
        "  \"\"\"\n",
        "  Load the model from the path directory provided\n",
        "  \"\"\"\n",
        "  checkpoint = torch.load(save_path)\n",
        "  model_state_dict = checkpoint['state_dict']\n",
        "  model = XLNetForMultiLabelSequenceClassification(num_labels=model_state_dict[\"classifier.weight\"].size()[0])\n",
        "  model.load_state_dict(model_state_dict)\n",
        "\n",
        "  epochs = checkpoint[\"epochs\"]\n",
        "  lowest_eval_loss = checkpoint[\"lowest_eval_loss\"]\n",
        "  train_loss_hist = checkpoint[\"train_loss_hist\"]\n",
        "  valid_loss_hist = checkpoint[\"valid_loss_hist\"]\n",
        "\n",
        "  return model, epochs, lowest_eval_loss, train_loss_hist, valid_loss_hist"
      ],
      "metadata": {
        "id": "h_zGrKF7XsOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "eQUWsyGNXsP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs,\\\n",
        "          optimizer,\\\n",
        "          train_dataloader, valid_dataloader,\\\n",
        "          train_loss_set=[], valid_loss_set = [],\\\n",
        "          lowest_eval_loss=None, start_epoch=0,\\\n",
        "          device=\"cpu\"\n",
        "          ):\n",
        "  \"\"\"\n",
        "  Train the model and save the model with the lowest validation loss\n",
        "  \"\"\"\n",
        "  # We'll store a number of quantities such as training and validation loss,\n",
        "  # validation accuracy, and timings.\n",
        "  training_stats = []\n",
        "  # Measure the total training time for the whole run.\n",
        "  total_t0 = time.time()\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  # trange is a tqdm wrapper around the python range function\n",
        "  for i in trange(num_epochs, desc=\"Epoch\"):\n",
        "    # if continue training from saved model\n",
        "    actual_epoch = start_epoch + i\n",
        "\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(actual_epoch, num_epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    num_train_samples = 0\n",
        "\n",
        "    # Train the data for one epoch\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 15 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Clear out the gradients (by default they accumulate)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        loss = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "        # store train loss\n",
        "        tr_loss += loss.item()\n",
        "        num_train_samples += b_labels.size(0)\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        # Update parameters and take a step using the computed gradient\n",
        "        optimizer.step()\n",
        "        #scheduler.step()\n",
        "\n",
        "    # Update tracking variables\n",
        "    epoch_train_loss = tr_loss/num_train_samples\n",
        "    train_loss_set.append(epoch_train_loss)\n",
        "\n",
        "#     print(\"Train loss: {}\".format(epoch_train_loss))\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(epoch_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put model in evaluation mode to evaluate loss on the validation set\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss = 0\n",
        "    num_eval_samples = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in valid_dataloader:\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # Telling the model not to compute or store gradients,\n",
        "        # saving memory and speeding up validation\n",
        "        with torch.no_grad():\n",
        "            # Forward pass, calculate validation loss\n",
        "            loss = model(input_ids=b_input_ids, attention_mask=b_input_mask, labels=b_labels)\n",
        "            # store valid loss\n",
        "            eval_loss += loss.item()\n",
        "            num_eval_samples += b_labels.size(0)\n",
        "\n",
        "    epoch_eval_loss = eval_loss/num_eval_samples\n",
        "    valid_loss_set.append(epoch_eval_loss)\n",
        "\n",
        "#     print(\"Valid loss: {}\".format(epoch_eval_loss))\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "#     avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "#     print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "#     avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(epoch_eval_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': actual_epoch,\n",
        "            'Training Loss': epoch_train_loss,\n",
        "            'Valid. Loss': epoch_eval_loss,\n",
        "#             'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "    if lowest_eval_loss == None:\n",
        "      lowest_eval_loss = epoch_eval_loss\n",
        "    else:\n",
        "      if epoch_eval_loss < lowest_eval_loss:\n",
        "        lowest_eval_loss = epoch_eval_loss\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"Training complete!\")\n",
        "\n",
        "  print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "  return model, train_loss_set, valid_loss_set, training_stats"
      ],
      "metadata": {
        "id": "rGQVhd3fXsRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "cwd = os.getcwd()\n",
        "model, train_loss_set, valid_loss_set, training_stats = train_model(model=model,\\\n",
        "                                                              num_epochs=num_epochs,\\\n",
        "                                                              optimizer=optimizer,\\\n",
        "                                                              train_dataloader=train_dataloader,\\\n",
        "                                                              valid_dataloader=validation_dataloader,\\\n",
        "                                                              device=\"cuda\"\n",
        "                                                              )"
      ],
      "metadata": {
        "id": "IRDFWNjtXsT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "# pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "id": "3bgaC5brXsVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cleaning text\n",
        "test['text_cleaned'] = list(map(lambda x:  preprocess_sentence_english(x),test['text']) )\n",
        "\n",
        "# Get the lists of sentences and their labels\n",
        "sentences = test.text_cleaned.values\n",
        "\n",
        "# input_ids = torch.from_numpy(input_ids)\n",
        "# attention_masks = torch.tensor(attention_masks)\n",
        "# labels = torch.tensor(labels)\n",
        "\n",
        "test_input_ids = tokenize_inputs(sentences, tokenizer, num_embeddings=120)\n",
        "test_attention_masks = create_attn_masks(test_input_ids)\n",
        "\n",
        "test[\"features\"] = test_input_ids.tolist()\n",
        "test[\"masks\"] = test_attention_masks"
      ],
      "metadata": {
        "id": "2UUI4pI2XsWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(model, df, device=\"cpu\", batch_size=16):\n",
        "  num_iter = math.ceil(df.shape[0]/batch_size)\n",
        "\n",
        "  pred_probs = []\n",
        "\n",
        "  #model.to(device)\n",
        "  #model.eval()\n",
        "\n",
        "  for i in range(num_iter):\n",
        "    df_subset = df.iloc[i*batch_size:(i+1)*batch_size,:]\n",
        "    X = df_subset[\"features\"].values.tolist()\n",
        "    masks = df_subset[\"masks\"].values.tolist()\n",
        "    X = torch.tensor(X)\n",
        "    masks = torch.tensor(masks, dtype=torch.long)\n",
        "    X = X.to(device)\n",
        "    masks = masks.to(device)\n",
        "    with torch.no_grad():\n",
        "      logits = model(input_ids=X, attention_mask=masks)\n",
        "      logits = logits.sigmoid().detach().cpu().numpy()\n",
        "#       pred_probs = np.vstack([pred_probs, logits])\n",
        "      pred_probs.extend(logits.tolist())\n",
        "\n",
        "  return pred_probs"
      ],
      "metadata": {
        "id": "JdfJzNuQX40A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics"
      ],
      "metadata": {
        "id": "ttrMKZDPX426"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probs = generate_predictions(model, test, device=\"cuda\", batch_size=16)\n",
        "# pred_probs\n",
        "statistics.mean(pred_probs)\n",
        "\n",
        "test['target'] = pred_probs\n",
        "test['target'] = np.array(test['target'] >= 0.5, dtype='int')"
      ],
      "metadata": {
        "id": "OKr8AzX-X448"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score,precision_recall_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from numpy import trapz\n",
        "from scipy.integrate import simps\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_curve, roc_auc_score,balanced_accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import average_precision_score,cohen_kappa_score"
      ],
      "metadata": {
        "id": "-2GpUNFxX47C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Evaluate(labels, predictions, p=0.5):\n",
        "    CM= confusion_matrix(labels, predictions > p)\n",
        "    TN = CM[0][0]\n",
        "    FN = CM[1][0]\n",
        "    TP = CM[1][1]\n",
        "    FP = CM[0][1]\n",
        "    print(' (True Negatives): {}'.format(TN))\n",
        "    print(' (False Negatives):  {}'.format(FN))\n",
        "    print(' (True Positives): {}'.format(TP))\n",
        "    print('(False Positives):{}'.format(FP))\n",
        "    print('Total positive : ', np.sum(CM[1]))\n",
        "    auc = roc_auc_score(labels, predictions)\n",
        "    norm_acc = accuracy_score(labels, predictions)\n",
        "    prec=precision_score(labels, predictions>0.5)\n",
        "    rec=recall_score(labels, predictions>0.5)\n",
        "     # calculate F1 score\n",
        "    f1 = f1_score(labels, predictions>p)\n",
        "    print('auc :{}'.format(auc))\n",
        "    print('precision :{}'.format(prec))\n",
        "    print('recall :{}'.format(rec))\n",
        "    print('f1 :{}'.format(f1))\n",
        "    # Compute Precision-Recall and plot curve\n",
        "    precision, recall, thresholds = precision_recall_curve(labels, predictions >0.5)\n",
        "    #use the trapezoidal rule to calculate the area under the precion-recall curve\n",
        "    area =  trapz(recall, precision)\n",
        "\n",
        "    #area =  simps(recall, precision)\n",
        "    print(\"Area Under Precision Recall  Curve(AP): %0.4f\" % area)   #should be same as AP?\n",
        "    average_precision = average_precision_score(labels, predictions>0.5)\n",
        "    print(\"average precision: %0.4f\" % average_precision)\n",
        "    kappa = cohen_kappa_score(labels, predictions>0.5)\n",
        "    print('kappa :{}'.format(kappa))\n",
        "    balanced_accuracy = balanced_accuracy_score(labels, predictions>0.5)\n",
        "    print('balanced_accuracy :{}'.format(balanced_accuracy))\n",
        "\n",
        "    return (auc, prec, rec, f1, average_precision, kappa, balanced_accuracy, norm_acc)\n",
        "\n",
        "\n",
        "Evaluate(test['isHate'], np.asarray(pred_probs) >0.5)"
      ],
      "metadata": {
        "id": "BiPyomZTX49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zm4bfakAX4-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zqIFIH-RX5Aw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}